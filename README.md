# mtop

![CI](https://github.com/jeremyeder/mtop/workflows/CI/badge.svg)
![Tests](https://img.shields.io/badge/tests-53%20passing-green.svg)
![Coverage](https://img.shields.io/badge/coverage-comprehensive-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![Quality](https://img.shields.io/badge/code%20quality-production%20ready-green.svg)

`mtop` (Model Top) is a mock CLI tool for debugging and simulating `LLMInferenceService` CRDs in a Kubernetes-like environment â€” without requiring a live cluster. It's designed for SREs, ML engineers, and platform teams to simulate rollouts, test failure modes, and inspect the status of LLM-serving infrastructure offline.

> **Note**: This project was initially generated by ChatGPT but completely rewritten by Claude due to severe structural issues in the original code.

## ğŸ¤ Collaboration

This project uses a collaborative development approach between Jeremy and Claude through GitHub issues. See [COLLABORATION.md](./COLLABORATION.md) for our workflow documentation.

**Current Focus**: Building GPU Heartbeat & SLO Convergence demo system with 45 tracked issues across 4 development phases.

---

## ğŸš€ Features

- âœ… Offline simulation of up to 100 `LLMInferenceService` CRs
- âœ… Mock support for `LLMInferenceServiceConfig`
- âœ… Full CRUD support on mocked CRs
- âœ… Realistic rollout playback (`play rollout`)
- âœ… Live-style watch command (`watch`) to track CR status changes
- âœ… Log simulation for individual model services
- âœ… Configurable via file structure (`./mocks/`)
- âœ… **mtop**: Real-time LLM inference monitoring (like `htop` for LLMs)

---

## ğŸ“¦ Structure

```
mtop/
â”œâ”€â”€ mtop                       # Python CLI entry point
â”œâ”€â”€ mocks/
â”‚   â”œâ”€â”€ crs/                   # LLMInferenceService CRs (20 included)
â”‚   â”œâ”€â”€ config/                # Global LLMInferenceServiceConfig mock
â”‚   â”œâ”€â”€ pod_logs/              # Simulated logs for LLMs
â”‚   â””â”€â”€ topologies/            # Rollout scenarios
```

---

## ğŸ›  Usage

```bash
chmod +x mtop
./mtop list                         # List all mocked LLMInferenceServices
./mtop check llm-005                # Inspect a specific CR
./mtop logs llm-005                 # View logs for a model
./mtop config                       # Show global LLM config
./mtop delete llm-005               # Delete a mock CR
./mtop create file.json             # Create CR from file
./mtop simulate canary              # Simulate canary rollout
./mtop                              # Real-time LLM inference monitoring
```

---

## ğŸ”¥ mtop: Real-time LLM Monitoring

`mtop` provides real-time monitoring of LLM inference services, similar to `htop` but specifically designed for LLM workloads.

### Features
- **Real-time metrics**: QPS, CPU usage, error rates, latency
- **Multi-model monitoring**: Track multiple LLM services simultaneously  
- **Dual-mode operation**: Works with both mock data and live clusters
- **Interactive display**: Live-updating terminal interface
- **Cluster overview**: Aggregate statistics and health indicators

### Usage

```bash
# Monitor using mock data (default)
./mtop

# Monitor live cluster
./mtop --mode live

# Monitor specific namespace
./mtop --namespace production

# Custom refresh rate
./mtop --interval 1.0

# Direct execution
./mtop                        # Real-time monitoring
```

### Display

```
ğŸš€ mtop - LLM Inference Monitor
Mode: mock | Namespace: default | Runtime: 45s | Sort: qps
Total QPS: 12,847 â€¢ Models: 34/34 healthy â€¢ Replicas: 127
Avg CPU: 52.3% â€¢ Avg Errors: 0.8%
Controls: Ctrl+C to quit | Sort by: qps

â”Œâ”€â”€â”€ ğŸ”¥ Live LLM Inference Traffic â”€â”€â”€â”
â”‚ Model                  Status    QPS   CPU   Errors  Latency  Replicas â”‚
â”‚ llama-3-70b-instruct   ğŸŸ¢ Ready   2,847  45%   0.2%    127ms    8       â”‚
â”‚ gpt-4-turbo           ğŸŸ¢ Ready   2,234  62%   0.1%    98ms     6       â”‚
â”‚ claude-3-opus         ğŸŸ¢ Ready   1,923  58%   0.3%    145ms    5       â”‚
â”‚ mixtral-8x7b-instruct ğŸŸ¢ Ready   1,445  71%   0.5%    156ms    4       â”‚
â”‚ ...                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Requirements

mtop requires the `rich` library for terminal display:

```bash
pip install rich
```

---

## ğŸ¬ Rollout Simulation

```bash
./mtop simulate canary
./mtop simulate bluegreen
./mtop simulate rolling
./mtop simulate shadow
```

Watch rollouts with animation:

```bash
./watch_rollout.py --topology rolling --autoplay --delay 2
```

---

## ğŸŒ Live Cluster Support

`mtop` can operate in **live mode** using actual Kubernetes resources.

### ğŸ” Modes

| Mode   | Description                       |
|--------|-----------------------------------|
| `mock` | Use local files in `./mocks/`     |
| `live` | Use kubernetes API to talk to a live cluster|

### ğŸ”§ Set the Mode

Via environment variable:

```bash
export LLD_MODE=live
./mtop list
```

Or per-command:

```bash
./mtop --mode live list
./mtop --mode mock list
```

---

## ğŸ§ª Development & Testing

**Requires: Python 3.11+**

The tool will check your Python version on startup and exit with an error if you're running an older version.

### Code Quality Features
- âœ… **Comprehensive Testing**: 53 tests including unit and integration tests
- âœ… **Type Hints**: Full type annotations for better IDE support
- âœ… **Security Scanning**: Automated vulnerability scanning with safety and bandit
- âœ… **Code Quality Gates**: Coverage thresholds and complexity checks
- âœ… **Dependency Management**: Automated updates with Dependabot
- âœ… **Error Handling**: Graceful error handling for all operations

### Running Tests
```bash
# Install test dependencies
pip install -r requirements.txt

# Run all tests
python3 -m pytest tests/ -v

# Run with coverage
python3 -m pytest tests/ --cov=. --cov-report=term
```

### Dependencies
See `requirements.txt` for pinned dependency versions with security scanning.

---

## Installation

### 1. Install Python dependencies

**Requirements: Python 3.11 or later**

```bash
# Check your Python version
python3 --version

# Install dependencies
pip install -r requirements.txt
```

### 2. Make executable

```bash
chmod +x mtop
```

### 3. Test installation

```bash
./mtop help
./mtop list
```

---

## ğŸ“œ License

MIT

---

## ğŸ¤ Contributing

Pull requests welcome for:
- Additional rollout topologies
- New simulation features
- Improved error handling
- Enhanced testing